{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 - IART - Supervised Learning\n",
    "\n",
    "### Adapted from Notebook by [Randal S. Olson](http://www.randalolson.com/), supported by [Jason H. Moore](http://www.epistasis.org/)\n",
    "#### [University of Pennsylvania Institute for Bioinformatics](http://upibi.org/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Iris flower extended data set –Classification using different Algorithms.\n",
    "Continuing with the Iris dataset, suppose that we have Iris already identified in the 3 classes but now we also have the Iris packed in different types of packages: “Simple – 0”, “Gift – 1” and “Luxury – 2”. We also have a new variable “price” with three possibilities: “Low”, “Medium”, “High”.\n",
    "\n",
    "We now have a different classification problem in which we want to predict the “price” classification based on the remaining characteristics: sepal_length_cm, sepal_width_cm, petal_length_cm, petal_width_cm, iris_type, and package.\n",
    "\n",
    "a) Create a new notebook and start by importing the needed libraries.\n",
    "\n",
    "b) Read the data from the CSV file and check the data using the head(), describe(), and other\n",
    "Pandas commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_cm</th>\n",
       "      <th>sepal_width_cm</th>\n",
       "      <th>petal_length_cm</th>\n",
       "      <th>petal_width_cm</th>\n",
       "      <th>iris_type</th>\n",
       "      <th>package</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm  \\\n",
       "0              5.1             3.5              1.4             0.2   \n",
       "1              4.9             3.0              1.4             0.2   \n",
       "2              4.7             3.2              1.3             0.2   \n",
       "3              4.6             3.1              1.5             0.2   \n",
       "4              5.0             3.6              1.4             0.2   \n",
       "\n",
       "     iris_type  package   price  \n",
       "0  Iris-setosa        2  Medium  \n",
       "1  Iris-setosa        1     Low  \n",
       "2  Iris-setosa        0     Low  \n",
       "3  Iris-setosa        0     Low  \n",
       "4  Iris-setosa        0     Low  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_data = pd.read_csv('iris-data-new2.csv')\n",
    "\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_cm</th>\n",
       "      <th>sepal_width_cm</th>\n",
       "      <th>petal_length_cm</th>\n",
       "      <th>petal_width_cm</th>\n",
       "      <th>package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.847651</td>\n",
       "      <td>3.059732</td>\n",
       "      <td>3.775168</td>\n",
       "      <td>1.209732</td>\n",
       "      <td>0.442953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.799542</td>\n",
       "      <td>0.430104</td>\n",
       "      <td>1.758720</td>\n",
       "      <td>0.762191</td>\n",
       "      <td>0.710753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm  \\\n",
       "count       149.000000      149.000000       149.000000      149.000000   \n",
       "mean          5.847651        3.059732         3.775168        1.209732   \n",
       "std           0.799542        0.430104         1.758720        0.762191   \n",
       "min           4.400000        2.000000         1.000000        0.100000   \n",
       "25%           5.100000        2.800000         1.600000        0.300000   \n",
       "50%           5.800000        3.000000         4.400000        1.300000   \n",
       "75%           6.400000        3.300000         5.100000        1.800000   \n",
       "max           7.900000        4.400000         6.900000        2.500000   \n",
       "\n",
       "          package  \n",
       "count  149.000000  \n",
       "mean     0.442953  \n",
       "std      0.710753  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      2.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Iris-setosa        49\n",
       "Name: iris_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data['iris_type'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using only the attribute sepal_length_cm, sepal_width_cm, petal_length_cm, petal_width_cm, fit a simple decision tree model to the data, using holdout, with 75% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Variables and Target\n",
    "x_decision = iris_data[['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']]\n",
    "y_decision = iris_data['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_decision_train, x_decision_test, y_decision_train, y_decision_test = train_test_split(x_decision, y_decision, test_size=0.75, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_decision_train, y_decision_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Analyze the accuracy, precision, recall and f-measure achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.76      0.81      0.79        16\n",
      "         Low       0.86      0.75      0.80        57\n",
      "      Medium       0.62      0.72      0.67        39\n",
      "\n",
      "    accuracy                           0.75       112\n",
      "   macro avg       0.75      0.76      0.75       112\n",
      "weighted avg       0.76      0.75      0.75       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "score_decision = clf.score(x_decision_test, y_decision_test)\n",
    "print(\"Accuracy:\", score_decision)\n",
    "\n",
    "y_decision_pred = clf.predict(x_decision_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_decision_test, y_decision_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Create and analyze a confusion matrix of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[13  0  3]\n",
      " [ 0 43 14]\n",
      " [ 4  7 28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_decision_test, y_decision_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Using only the attribute sepal_length_cm, sepal_width_cm, petal_length_cm,\n",
    "petal_width_cm, fit a simple nearest neighbor model to the data using holdout with 75% for\n",
    "training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_neighbor = iris_data[['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']]\n",
    "y_neighbor = iris_data['price']\n",
    "\n",
    "x_neighbor_train, x_neighbor_test, y_neighbor_train, y_neighbor_test = train_test_split(x_neighbor, y_neighbor, test_size=0.25, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_neighbor_train, y_neighbor_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Analyze the accuracy, precision, recall and f-measure achieved and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8157894736842105\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      0.57      0.73         7\n",
      "         Low       0.89      0.89      0.89        18\n",
      "      Medium       0.69      0.85      0.76        13\n",
      "\n",
      "    accuracy                           0.82        38\n",
      "   macro avg       0.86      0.77      0.79        38\n",
      "weighted avg       0.84      0.82      0.81        38\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4  0  3]\n",
      " [ 0 16  2]\n",
      " [ 0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diogofonte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/diogofonte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score_neighbor = knn.score(x_neighbor_test, y_neighbor_test)\n",
    "print(\"Accuracy:\", score_neighbor)\n",
    "\n",
    "y_neighbor_pred = knn.predict(x_neighbor_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_neighbor_test, y_neighbor_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_neighbor_test, y_neighbor_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Use two different methods for balancing the dataset and repeat the previous analyses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### UnderSampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Confusion Matrix:\n",
      "[[5 0 3]\n",
      " [0 5 1]\n",
      " [1 2 2]]\n",
      "\n",
      "Undersampling Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.83      0.62      0.71         8\n",
      "         Low       0.71      0.83      0.77         6\n",
      "      Medium       0.33      0.40      0.36         5\n",
      "\n",
      "    accuracy                           0.63        19\n",
      "   macro avg       0.63      0.62      0.62        19\n",
      "weighted avg       0.66      0.63      0.64        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diogofonte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# pip install imbalanced-learn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "x_balance_under = iris_data[['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']]\n",
    "y_balance_under = iris_data['price']\n",
    "\n",
    "# UnderSampling Method\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "x_rus, y_rus = rus.fit_resample(x_balance_under, y_balance_under)\n",
    "\n",
    "x_train_rus, x_test_rus, y_train_rus, y_test_rus = train_test_split(x_rus, y_rus, test_size=0.25, random_state=42)\n",
    "\n",
    "knn_rus = KNeighborsClassifier()\n",
    "knn_rus.fit(x_train_rus, y_train_rus)\n",
    "\n",
    "y_pred_rus = knn_rus.predict(x_test_rus)\n",
    "\n",
    "print(\"Undersampling Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_rus, y_pred_rus))\n",
    "\n",
    "print(\"\\nUndersampling Classification Report:\")\n",
    "print(classification_report(y_test_rus, y_pred_rus))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OverSampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling Confusion Matrix:\n",
      "[[17  0  2]\n",
      " [ 0 13  3]\n",
      " [ 5  3 11]]\n",
      "Oversampling Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.77      0.89      0.83        19\n",
      "         Low       0.81      0.81      0.81        16\n",
      "      Medium       0.69      0.58      0.63        19\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.76      0.76      0.76        54\n",
      "weighted avg       0.75      0.76      0.75        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diogofonte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "x_balance_over = iris_data[['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']]\n",
    "y_balance_over = iris_data['price']\n",
    "\n",
    "# OverSampling Method\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(x_balance_over, y_balance_over)\n",
    "\n",
    "X_train_ros, X_test_ros, y_train_ros, y_test_ros = train_test_split(X_ros, y_ros, test_size=0.25, random_state=42)\n",
    "\n",
    "knn_ros = KNeighborsClassifier()\n",
    "knn_ros.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "y_pred_ros = knn_ros.predict(X_test_ros)\n",
    "\n",
    "print(\"Oversampling Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_ros, y_pred_ros))\n",
    "\n",
    "print(\"\\nOversampling Classification Report:\")\n",
    "print(classification_report(y_test_ros, y_pred_ros))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Using all the attributes available, and the balanced dataset, fit distinct models such as\n",
    "Nearest Neighbor, Decision Trees, SVMs and Neural Networks to the data and try different\n",
    "configuration parameters, using holdout with 75% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all other imports done previously\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# export the balanced dataset to the file iris-data-balanced.csv\n",
    "\n",
    "iris_data = pd.read_csv('iris-data-balanced.csv')\n",
    "X = iris_data.drop(['price'], axis=1)\n",
    "y = iris_data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "over_sampler = RandomOverSampler(sampling_strategy='minority')\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "under_sampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# K-Nearest Neighbor\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_over, y_train_over)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"K-Nearest Neighbor:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_knn, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_knn, average='macro'))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_knn, average='macro'))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "dt.fit(X_train_under, y_train_under)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(\"Decision Tree:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_dt, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_dt, average='macro'))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_dt, average='macro'))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "# Support Vector Machine - SVC\n",
    "svm = SVC(kernel='rbf', C=1, gamma=0.1)\n",
    "svm.fit(X_train_under, y_train_under)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"Support Vector Machine:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm, average='macro'))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_svm, average='macro'))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "# Neural Network\n",
    "nn = MLPClassifier(hidden_layer_sizes=(10, 5), activation='logistic', solver='sgd', learning_rate_init=0.01, max_iter=1000)\n",
    "nn.fit(X_train_over, y_train_over)\n",
    "y_pred_nn = nn.predict(X_test)\n",
    "print(\"Neural Network:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_nn, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_nn, average='macro'))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_nn, average='macro'))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nn))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) Analyze the accuracy, precision, recall and f-measure achieved and the confusion matrix."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Repeat the previous analysis but experimenting with all models using 5-fold Cross-\n",
    "Validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l) Use Grid Search to define the best parameters for the best two algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m) Analyze the accuracy, precision, recall, f-measure and the confusion matrix for the best\n",
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
